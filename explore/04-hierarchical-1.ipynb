{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Hierarchical class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores the base functionality of Hierarchical as this base functionality is introduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, Hierarchical is indeed instantiated as a subclass of Sequential, but only inherits the methods that specify how the layer architecture works. If more general architectures are added, the actual implementation will be moved up. Currently, this implementation already involves the general Model API in keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods in Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0830 16:04:13.270175 139747659605824 deprecation_wrapper.py:119] From /home/sflippl/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "seq = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0828 14:54:07.034281 140407269582656 deprecation_wrapper.py:119] From /home/sflippl/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0828 14:54:07.037168 140407269582656 deprecation_wrapper.py:119] From /home/sflippl/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq.add(keras.layers.Dense(10, input_shape=(4, )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                50        \n",
      "=================================================================\n",
      "Total params: 50\n",
      "Trainable params: 50\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, the thing we must add is a possibility to infer arbitrary states; essentially a state layer. Later, this will be ample opportunity to specify different kinds of state layers (think probabilistic, a la Srinivasan, etc.). Later, we may thus have more than two different modes of estimation, but for now, we have state and weight parameter estimation. This means that effectively, we have multiple sequential models -- which also means that we might as well just explicitly have an entirely new class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall UI should enable state-to-state thinking. Conceptually, there are two levels of a predictive coding model: on one level, there are the state inference layers. On the other hand, each of these inferred states is being used to predict the state blow, the lowest state being actually observed. The supernetworks should be specified in a bottom-up fashion, whereas the subnetworks should be specified in a top-down fashion. When Hierarchical is initialized, it should thus be initialized in a top-down fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following syntax thus seems sensible:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hpc = pc.Hierarchical()\n",
    "hpc.add(\n",
    "    keras.Sequential(\n",
    "        [pc.layers.State(input_shape=(4, )),\n",
    "         keras.layers.Dense(10),\n",
    "         pc.layers.StateEstimation()]\n",
    "    )\n",
    ")\n",
    "print(hpc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, as a more complex example:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nl_hpc = pc.Hierarchical()\n",
    "nl_hpc.add(pc.layers.State(input_shape=(4, )))\n",
    "nl_hpc.add(\n",
    "    keras.Sequential(\n",
    "         keras.layers.activation('relu', input_shape=(4, )),\n",
    "         keras.layers.Dense(10),\n",
    "         pc.layers.StateEstimation()]\n",
    "    )\n",
    ")\n",
    "nl_hpc.add(pc.layers.StateEstimation())\n",
    "# Current state estimation loop closed. Moving up one tier.\n",
    "nl_hpc.add(pc.layers.State(input_shape=(4, )))\n",
    "\n",
    "nl_hpc.add(\n",
    "    keras.Sequential(\n",
    "         keras.layers.Dense(10),\n",
    "         keras.layers.activation('relu'),\n",
    "         keras.layers.Dense(4)]\n",
    "    )\n",
    ")\n",
    "print(nl_hpc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pro: Hierarchical models can be built in a bottom up fashion.\n",
    "Con: There's a somewhat unnecessary doubling of state estimation and state -- or at least the input shape there.\n",
    "However, I can see certain advantages with that kind of verbosity, as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, I will implement the pure interface plus printing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revamp: There are essentially three different modi: adding the state tiers, adding the tier models, and adding the connections between the tiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 44        \n",
      "=================================================================\n",
      "Total params: 94\n",
      "Trainable params: 94\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq = keras.Sequential()\n",
    "seq.add(keras.layers.Dense(10, input_shape=(4, )))\n",
    "seq.add(keras.layers.Activation('relu'))\n",
    "seq.add(keras.layers.Dense(4))\n",
    "seq.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nl_hpc = pc.Hierarchical()\n",
    "nl_hpc.add_tier(shape=(10, ))\n",
    "# Adding 'Tier 0'.\n",
    "nl_hpc.add_tier(shape=(4, ))\n",
    "# Adding 'Tier 1'.\n",
    "nl_hpc.add_tier(shape=(2, ), name='Final Tier')\n",
    "# Adding 'Final Tier' (Tier 2).\n",
    "nl_hpc.summary()\n",
    "# -------------------------------------------------------------------\n",
    "# Layer (type)               Output Shape               Param #\n",
    "# ===================================================================\n",
    "# TIER_2\n",
    "# -------------------------------------------------------------------\n",
    "# (Missing Model.)\n",
    "# -------------------------------------------------------------------\n",
    "# (Missing State Prediction.)\n",
    "# -------------------------------------------------------------------\n",
    "# TIER_1\n",
    "# -------------------------------------------------------------------\n",
    "# (Missing Model.)\n",
    "# -------------------------------------------------------------------\n",
    "# (Missing State Prediction.)\n",
    "# -------------------------------------------------------------------\n",
    "# TIER_0\n",
    "# ==================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly, we separate the user interface from the implementation via the appropriate class methods. Though I have not looked at that yet, this should make an alternative backend to Tensorflow easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kind of interface has now been achieved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0830 16:04:18.893996 139747659605824 deprecation_wrapper.py:119] From /home/sflippl/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0830 16:04:18.905709 139747659605824 deprecation_wrapper.py:119] From /home/sflippl/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tier 1: tier_1\n",
      "## Connecting Predictor\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 4)                 44        \n",
      "=================================================================\n",
      "Total params: 44\n",
      "Trainable params: 44\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "## Connection State Prediction\n",
      "(No state prediction defined.)\n",
      "# Tier 0: tier_0\n"
     ]
    }
   ],
   "source": [
    "import predicode as pc\n",
    "import keras\n",
    "hpc = pc.Hierarchical()\n",
    "hpc.add_tier(shape=(10, ))\n",
    "hpc.add_tier(shape=(4, ))\n",
    "hpc.predictor = keras.Sequential()\n",
    "hpc.predictor.add(keras.layers.Dense(4, input_shape=(10, )))\n",
    "hpc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we tackle the real meat of Hierarchical: the estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our estimation consists of an interplay between state variables and their corresponding minimizers, and models and their corresponding minimizers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "art = pc.decaying_multi_normal(dimensions=10, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "tier_0 = tf.constant(art, name = 'tier_0', dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "tier_1_initial = pc.init('random', columns=4, rows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "tier_1 = tf.Variable(tier_1_initial, name = 'hierarchical_1_tier_1', dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_1 = keras.Sequential([keras.layers.Dense(10, input_shape=(4, ), use_bias=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f18bb8c3b10>"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_1 = predictor_1(tier_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = keras.losses.mean_squared_error(tier_0, predicted_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25360444 0.22708221 0.0162115  0.02750648 0.11611382 0.05579837\n",
      " 0.01782483 0.01400409 0.18456575 0.2195266  0.03926224 0.11332171\n",
      " 0.16874531 0.18739022 0.48242077 0.18214998 0.3583482  0.13900527\n",
      " 0.761213   0.29731005 0.01002112 0.10913886 0.07890564 0.08191447\n",
      " 0.01689442 0.00465213 0.02475609 0.3952284  0.17162569 0.0084704\n",
      " 0.00558436 0.03944265 0.05324567 0.05877722 0.00574681 0.04137947\n",
      " 0.42664728 0.0127202  0.16638245 0.05489131 0.01352558 0.15624201\n",
      " 0.1070043  0.11062206 0.02763974 0.02389851 0.0126999  0.4434076\n",
      " 0.08436457 0.14109716 0.13791429 0.24067771 0.01010384 0.01050533\n",
      " 0.04059715 0.03878767 0.13854215 0.24737802 0.05857478 0.26247895\n",
      " 0.02099425 0.09011039 0.04268298 0.22133084 0.00573754 0.03962309\n",
      " 0.21524036 0.05308912 0.04217167 0.28271243 0.20865652 0.09021195\n",
      " 0.02156907 0.03422244 0.31455955 0.06558277 0.20684285 0.16278024\n",
      " 0.25961897 0.91579616 0.15638778 0.02675242 0.23569699 0.02741941\n",
      " 0.0320649  0.17602226 0.19689794 0.19700928 0.1530825  0.1108022\n",
      " 0.09558789 0.04417872 0.02439235 0.24044318 0.02069707 0.94822675\n",
      " 0.08234616 0.3691011  0.02836876 0.07287588]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_optimizer = tf.train.GradientDescentOptimizer(learning_rate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_15:0' shape=(100,) dtype=float32>"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_step = state_optimizer.minimize(loss, var_list=(tier_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03243238  0.2186738  -0.02018487  0.02575708]\n",
      "[-0.13920164 -0.02962834  0.09834187  0.00599605]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(tier_1)[0, ])\n",
    "    sess.run(state_step)\n",
    "    print(sess.run(tier_1)[0, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03243238  0.2186738  -0.02018487  0.02575708]\n",
      "[-0.4991267  -0.5025747   0.26580867 -0.2504718 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(tier_1)[0, ])\n",
    "    for i in range(10):\n",
    "        sess.run(state_step)\n",
    "    print(sess.run(tier_1)[0, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictor estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_optimizer = tf.train.GradientDescentOptimizer(learning_rate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_loss = tf.math.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_16:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_step = predictor_optimizer.minimize(predictor_loss, var_list = predictor_1.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14465778\n",
      "[array([[-1.7108925e-02, -2.5487083e-01,  3.9950970e-01, -7.4577510e-01,\n",
      "        -5.3083360e-02, -1.3094580e-01,  4.9180683e-01, -2.6958224e-01,\n",
      "        -3.0999517e-02, -3.9294282e-01],\n",
      "       [-3.4616698e-02, -1.8440261e-02, -1.9149692e-01, -1.5493933e-03,\n",
      "         1.6140562e-01,  8.5759163e-02,  1.4126500e-01,  8.5966391e-03,\n",
      "         1.0085887e-01, -1.2573749e-01],\n",
      "       [-1.4346266e-01, -2.2139332e-01,  1.3662139e+00, -1.8113140e+00,\n",
      "        -5.9843414e-02, -6.2998980e-01,  5.7082003e-01, -7.4901414e-01,\n",
      "        -7.6817781e-02, -5.1907384e-01],\n",
      "       [-2.5155081e-03,  1.9905902e-01, -2.5483847e-01,  3.8675079e-01,\n",
      "        -4.3461457e-02,  1.7035905e-01, -1.9656603e-01,  9.7926654e-02,\n",
      "        -9.1270842e-02,  2.2500600e-01]], dtype=float32)]\n",
      "[0.3333633  0.2093298  0.4824954  0.34900895]\n",
      "[array([[-1.7108925e-02, -2.5487083e-01,  3.9950970e-01, -7.4577510e-01,\n",
      "        -5.3083360e-02, -1.3094580e-01,  4.9180683e-01, -2.6958224e-01,\n",
      "        -3.0999517e-02, -3.9294282e-01],\n",
      "       [-3.4616698e-02, -1.8440261e-02, -1.9149692e-01, -1.5493933e-03,\n",
      "         1.6140562e-01,  8.5759163e-02,  1.4126500e-01,  8.5966391e-03,\n",
      "         1.0085887e-01, -1.2573749e-01],\n",
      "       [-1.4346266e-01, -2.2139332e-01,  1.3662139e+00, -1.8113140e+00,\n",
      "        -5.9843414e-02, -6.2998980e-01,  5.7082003e-01, -7.4901414e-01,\n",
      "        -7.6817781e-02, -5.1907384e-01],\n",
      "       [-2.5155081e-03,  1.9905902e-01, -2.5483847e-01,  3.8675079e-01,\n",
      "        -4.3461457e-02,  1.7035905e-01, -1.9656603e-01,  9.7926654e-02,\n",
      "        -9.1270842e-02,  2.2500600e-01]], dtype=float32)]\n",
      "[0.33443058 0.20007388 0.47761002 0.33019543]\n",
      "[array([[-0.02800105, -0.2516233 ,  0.38944447, -0.76274043, -0.03461138,\n",
      "        -0.08242299,  0.51843655, -0.293727  , -0.07988086, -0.34936225],\n",
      "       [ 0.01956737,  0.01082424, -0.1935043 , -0.05411317,  0.21530508,\n",
      "         0.14925787,  0.1737539 ,  0.04358952,  0.04014774, -0.06581552],\n",
      "       [-0.23382972, -0.27691868,  1.3241308 , -1.7810346 , -0.09441141,\n",
      "        -0.6657272 ,  0.56667805, -0.8357375 , -0.11128724, -0.51308745],\n",
      "       [ 0.00728293,  0.21600452, -0.25493103,  0.35754332,  0.0953257 ,\n",
      "         0.26614985, -0.1548116 ,  0.0708317 , -0.2800484 ,  0.29095486]],\n",
      "      dtype=float32)]\n",
      "0.00024200961\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(predictor_loss))\n",
    "    for i in range(1000):\n",
    "        sess.run(predictor_step)\n",
    "    print(predictor_1.get_weights())\n",
    "    for i in range(100):\n",
    "        sess.run(state_step)\n",
    "    print(sess.run(tier_1)[0, ])\n",
    "    print(predictor_1.get_weights())\n",
    "    for i in range(100):\n",
    "        sess.run(predictor_step)\n",
    "    for i in range(100):\n",
    "        sess.run(state_step)\n",
    "    print(sess.run(tier_1)[0, ])\n",
    "    print(predictor_1.get_weights())\n",
    "    print(sess.run(predictor_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ought to have given us some intuition for how this process should work, so we will now single out the different steps. Clearly, the tiers should simply be Tensorflow variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_1.compile(tf.train.GradientDescentOptimizer(learning_rate=10), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0038\n",
      "Epoch 1/1\n",
      " 1/50 [..............................] - ETA: 0s - loss: 4.0384e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function BaseSession._Callable.__del__ at 0x7f194df4ad40>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sflippl/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1473, in __del__\n",
      "    self._session._session, self._handle)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 871us/step - loss: 3.3246e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 869us/step - loss: 2.7726e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 2.6677e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 2.6462e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 2.6399e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 2.6360e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 887us/step - loss: 2.6320e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 2.6273e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 994us/step - loss: 2.6216e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 838us/step - loss: 2.6146e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 764us/step - loss: 2.6062e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 932us/step - loss: 2.5960e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 837us/step - loss: 2.5835e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 885us/step - loss: 2.5685e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 832us/step - loss: 2.5502e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 880us/step - loss: 2.5282e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 833us/step - loss: 2.5018e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 898us/step - loss: 2.4701e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 810us/step - loss: 2.4324e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 2.3879e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 901us/step - loss: 2.3356e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 810us/step - loss: 2.2748e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 2.2049e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 833us/step - loss: 2.1255e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 2.0366e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 938us/step - loss: 1.9387e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 908us/step - loss: 1.8327e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 801us/step - loss: 1.7201e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 867us/step - loss: 1.6029e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 849us/step - loss: 1.4835e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 849us/step - loss: 1.3643e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 1.2480e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 901us/step - loss: 1.1369e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 933us/step - loss: 1.0327e-04\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 9.3691e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 769us/step - loss: 8.5034e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 956us/step - loss: 7.7330e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 958us/step - loss: 7.0570e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 872us/step - loss: 6.4710e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 848us/step - loss: 5.9684e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 5.5412e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 5.1809e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 875us/step - loss: 4.8790e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 826us/step - loss: 4.6274e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4.4186e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 828us/step - loss: 4.2461e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 4.1039e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 886us/step - loss: 3.9870e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 820us/step - loss: 3.8912e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 915us/step - loss: 3.8127e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 775us/step - loss: 3.7485e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 3.6961e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 827us/step - loss: 3.6534e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 888us/step - loss: 3.6185e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 826us/step - loss: 3.5901e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 780us/step - loss: 3.5669e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 859us/step - loss: 3.5481e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 817us/step - loss: 3.5327e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 867us/step - loss: 3.5202e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 3.5101e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 858us/step - loss: 3.5018e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 3.4951e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 3.4896e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 943us/step - loss: 3.4851e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 840us/step - loss: 3.4815e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 854us/step - loss: 3.4786e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 820us/step - loss: 3.4762e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 3.4742e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 3.4726e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 817us/step - loss: 3.4713e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 796us/step - loss: 3.4703e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 866us/step - loss: 3.4694e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 884us/step - loss: 3.4687e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 3.4682e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 969us/step - loss: 3.4677e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 3.4673e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 3.4670e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 3.4668e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 901us/step - loss: 3.4666e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 3.4664e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 825us/step - loss: 3.4663e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 937us/step - loss: 3.4662e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 3.4661e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 3.4660e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 785us/step - loss: 3.4659e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 777us/step - loss: 3.4659e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 933us/step - loss: 3.4659e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 915us/step - loss: 3.4658e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 796us/step - loss: 3.4658e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 3.4658e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 3.4658e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 783us/step - loss: 3.4657e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 871us/step - loss: 3.4657e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 834us/step - loss: 3.4657e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 820us/step - loss: 3.4657e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 3.4657e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 3.4657e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 844us/step - loss: 3.4657e-05\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 0s 805us/step - loss: 3.4657e-05\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op.run()\n",
    "    for i in range(100):\n",
    "        for i in range(1000):\n",
    "            state_step.run()\n",
    "        predictor_1.fit(tier_1, tier_0, steps_per_epoch=50, epochs=1)\n",
    "    final_weights = predictor_1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.decomposition as decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomp.PCA(10).fit(art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.21951185e+00, 1.47887111e-01, 1.78051538e-02, 2.19805505e-03,\n",
       "       2.92805709e-04, 4.94937281e-05, 6.15893716e-06, 6.60351392e-07,\n",
       "       1.10990880e-07, 1.06866469e-08])"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_weights = pca.components_[:4]\n",
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10)"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.24617272e-03, 1.50873588e-05, 1.14442212e-06, 2.81435079e-07])"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "angles = scipy.linalg.subspace_angles(final_weights[0].T, pca_weights.T)\n",
    "angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.00583555e-01, 8.64441984e-04, 6.55705576e-05, 1.61250422e-05])"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.rad2deg(angles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm indeed seems to find the PCA subspace. I am not sure why the accuracy is so low, though. (I had increased the iterations and nothing changed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_weights = final_weights[0] / np.linalg.norm(final_weights[0], 2, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "contribs = np.matmul(np.linalg.inv(pca.components_).T, normalized_weights.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (8734010135609)>"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lazytools_sflippl as lazytools\n",
    "lazytools.matrix_heatmap(contribs, pole=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This speaks a pretty clear language though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.07781646e+00, 1.08374561e+00, 9.05683455e-01, 9.18434088e-01,\n",
       "       4.56237665e-03, 1.25316886e-04, 1.45934388e-03, 3.39127943e-04,\n",
       "       2.85356887e-05, 3.78326325e-04])"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(contribs, 2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same precision, however. This implies reasonable confidence that all errors are numerical, and we can look at an optimization of that after the first implementation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
