{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# States (Version 0.2.0-beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## States object"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "state = pc.State({'state'{\n",
    "    'tier_0': np.array(...),\n",
    "    'latent_layer': np.array(...)\n",
    "}, {'prediction':{\n",
    "    'tier_0': np.array(...)\n",
    "}}, 'prediction_error':{...},\n",
    "    'order'['tier_0', 'latent_layer']}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import predicode as pc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = pc.States({'tier_0': {'state': np.array([1, 0]), 'prediction': np.array([0, 0])}}, order=['tier_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class File in module h5py._hl.files:\n",
      "\n",
      "class File(h5py._hl.group.Group)\n",
      " |  File(name, mode=None, driver=None, libver=None, userblock_size=None, swmr=False, **kwds)\n",
      " |  \n",
      " |  Represents an HDF5 file.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      File\n",
      " |      h5py._hl.group.Group\n",
      " |      h5py._hl.base.HLObject\n",
      " |      h5py._hl.base.CommonStateObject\n",
      " |      h5py._hl.base.MutableMappingHDF5\n",
      " |      h5py._hl.base.MappingHDF5\n",
      " |      collections.abc.MutableMapping\n",
      " |      collections.abc.Mapping\n",
      " |      collections.abc.Collection\n",
      " |      collections.abc.Sized\n",
      " |      collections.abc.Iterable\n",
      " |      collections.abc.Container\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |  \n",
      " |  __exit__(self, *args)\n",
      " |  \n",
      " |  __init__(self, name, mode=None, driver=None, libver=None, userblock_size=None, swmr=False, **kwds)\n",
      " |      Create a new file object.\n",
      " |      \n",
      " |      See the h5py user guide for a detailed explanation of the options.\n",
      " |      \n",
      " |      name\n",
      " |          Name of the file on disk.  Note: for files created with the 'core'\n",
      " |          driver, HDF5 still requires this be non-empty.\n",
      " |      mode\n",
      " |          r        Readonly, file must exist\n",
      " |          r+       Read/write, file must exist\n",
      " |          w        Create file, truncate if exists\n",
      " |          w- or x  Create file, fail if exists\n",
      " |          a        Read/write if exists, create otherwise (default)\n",
      " |      driver\n",
      " |          Name of the driver to use.  Legal values are None (default,\n",
      " |          recommended), 'core', 'sec2', 'stdio', 'mpio'.\n",
      " |      libver\n",
      " |          Library version bounds.  Currently only the strings 'earliest'\n",
      " |          and 'latest' are defined.\n",
      " |      userblock\n",
      " |          Desired size of user block.  Only allowed when creating a new\n",
      " |          file (mode w, w- or x).\n",
      " |      swmr\n",
      " |          Open the file in SWMR read mode. Only used when mode = 'r'.\n",
      " |      Additional keywords\n",
      " |          Passed on to the selected file driver.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  close(self)\n",
      " |      Close the file.  All open objects become invalid\n",
      " |  \n",
      " |  flush(self)\n",
      " |      Tell the HDF5 library to flush its buffers.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  attrs\n",
      " |      Attributes attached to this object\n",
      " |  \n",
      " |  driver\n",
      " |      Low-level HDF5 file driver used to open file\n",
      " |  \n",
      " |  fid\n",
      " |      File ID (backwards compatibility)\n",
      " |  \n",
      " |  filename\n",
      " |      File name on disk\n",
      " |  \n",
      " |  libver\n",
      " |      File format version bounds (2-tuple: low, high)\n",
      " |  \n",
      " |  mode\n",
      " |      Python mode used to open file\n",
      " |  \n",
      " |  swmr_mode\n",
      " |      Controls single-writer multiple-reader mode\n",
      " |  \n",
      " |  userblock_size\n",
      " |      User block size (in bytes)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h5py._hl.group.Group:\n",
      " |  \n",
      " |  __contains__(self, name)\n",
      " |      Test if a member name exists\n",
      " |  \n",
      " |  __delitem__(self, name)\n",
      " |      Delete (unlink) an item from this group.\n",
      " |  \n",
      " |  __getitem__(self, name)\n",
      " |      Open an object in the file\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Iterate over member names\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Number of members attached to this group\n",
      " |  \n",
      " |  __setitem__(self, name, obj)\n",
      " |      Add an object to the group.  The name must not already be in use.\n",
      " |      \n",
      " |      The action taken depends on the type of object assigned:\n",
      " |      \n",
      " |      Named HDF5 object (Dataset, Group, Datatype)\n",
      " |          A hard link is created at \"name\" which points to the\n",
      " |          given object.\n",
      " |      \n",
      " |      SoftLink or ExternalLink\n",
      " |          Create the corresponding link.\n",
      " |      \n",
      " |      Numpy ndarray\n",
      " |          The array is converted to a dataset object, with default\n",
      " |          settings (contiguous storage, etc.).\n",
      " |      \n",
      " |      Numpy dtype\n",
      " |          Commit a copy of the datatype as a named datatype in the file.\n",
      " |      \n",
      " |      Anything else\n",
      " |          Attempt to convert it to an ndarray and store it.  Scalar\n",
      " |          values are stored as scalar datasets. Raise ValueError if we\n",
      " |          can't understand the resulting array dtype.\n",
      " |  \n",
      " |  copy(self, source, dest, name=None, shallow=False, expand_soft=False, expand_external=False, expand_refs=False, without_attrs=False)\n",
      " |      Copy an object or group.\n",
      " |      \n",
      " |       The source can be a path, Group, Dataset, or Datatype object.  The\n",
      " |       destination can be either a path or a Group object.  The source and\n",
      " |       destinations need not be in the same file.\n",
      " |      \n",
      " |       If the source is a Group object, all objects contained in that group\n",
      " |       will be copied recursively.\n",
      " |      \n",
      " |       When the destination is a Group object, by default the target will\n",
      " |       be created in that group with its current name (basename of obj.name).\n",
      " |       You can override that by setting \"name\" to a string.\n",
      " |      \n",
      " |       There are various options which all default to \"False\":\n",
      " |      \n",
      " |        - shallow: copy only immediate members of a group.\n",
      " |      \n",
      " |        - expand_soft: expand soft links into new objects.\n",
      " |      \n",
      " |        - expand_external: expand external links into new objects.\n",
      " |      \n",
      " |        - expand_refs: copy objects that are pointed to by references.\n",
      " |      \n",
      " |        - without_attrs: copy object without copying attributes.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |       >>> f = File('myfile.hdf5')\n",
      " |       >>> f.listnames()\n",
      " |       ['MyGroup']\n",
      " |       >>> f.copy('MyGroup', 'MyCopy')\n",
      " |       >>> f.listnames()\n",
      " |       ['MyGroup', 'MyCopy']\n",
      " |  \n",
      " |  create_dataset(self, name, shape=None, dtype=None, data=None, **kwds)\n",
      " |      Create a new HDF5 dataset\n",
      " |      \n",
      " |      name\n",
      " |          Name of the dataset (absolute or relative).  Provide None to make\n",
      " |          an anonymous dataset.\n",
      " |      shape\n",
      " |          Dataset shape.  Use \"()\" for scalar datasets.  Required if \"data\"\n",
      " |          isn't provided.\n",
      " |      dtype\n",
      " |          Numpy dtype or string.  If omitted, dtype('f') will be used.\n",
      " |          Required if \"data\" isn't provided; otherwise, overrides data\n",
      " |          array's dtype.\n",
      " |      data\n",
      " |          Provide data to initialize the dataset.  If used, you can omit\n",
      " |          shape and dtype arguments.\n",
      " |      \n",
      " |      Keyword-only arguments:\n",
      " |      \n",
      " |      chunks\n",
      " |          (Tuple) Chunk shape, or True to enable auto-chunking.\n",
      " |      maxshape\n",
      " |          (Tuple) Make the dataset resizable up to this shape.  Use None for\n",
      " |          axes you want to be unlimited.\n",
      " |      compression\n",
      " |          (String or int) Compression strategy.  Legal values are 'gzip',\n",
      " |          'szip', 'lzf'.  If an integer in range(10), this indicates gzip\n",
      " |          compression level. Otherwise, an integer indicates the number of a\n",
      " |          dynamically loaded compression filter.\n",
      " |      compression_opts\n",
      " |          Compression settings.  This is an integer for gzip, 2-tuple for\n",
      " |          szip, etc. If specifying a dynamically loaded compression filter\n",
      " |          number, this must be a tuple of values.\n",
      " |      scaleoffset\n",
      " |          (Integer) Enable scale/offset filter for (usually) lossy\n",
      " |          compression of integer or floating-point data. For integer\n",
      " |          data, the value of scaleoffset is the number of bits to\n",
      " |          retain (pass 0 to let HDF5 determine the minimum number of\n",
      " |          bits necessary for lossless compression). For floating point\n",
      " |          data, scaleoffset is the number of digits after the decimal\n",
      " |          place to retain; stored values thus have absolute error\n",
      " |          less than 0.5*10**(-scaleoffset).\n",
      " |      shuffle\n",
      " |          (T/F) Enable shuffle filter.\n",
      " |      fletcher32\n",
      " |          (T/F) Enable fletcher32 error detection. Not permitted in\n",
      " |          conjunction with the scale/offset filter.\n",
      " |      fillvalue\n",
      " |          (Scalar) Use this value for uninitialized parts of the dataset.\n",
      " |      track_times\n",
      " |          (T/F) Enable dataset creation timestamps.\n",
      " |  \n",
      " |  create_group(self, name, track_order=False)\n",
      " |      Create and return a new subgroup.\n",
      " |      \n",
      " |      Name may be absolute or relative.  Fails if the target name already\n",
      " |      exists.\n",
      " |      \n",
      " |      track_order\n",
      " |          Track dataset/group creation order under this group if True.\n",
      " |  \n",
      " |  get(self, name, default=None, getclass=False, getlink=False)\n",
      " |      Retrieve an item or other information.\n",
      " |      \n",
      " |      \"name\" given only:\n",
      " |          Return the item, or \"default\" if it doesn't exist\n",
      " |      \n",
      " |      \"getclass\" is True:\n",
      " |          Return the class of object (Group, Dataset, etc.), or \"default\"\n",
      " |          if nothing with that name exists\n",
      " |      \n",
      " |      \"getlink\" is True:\n",
      " |          Return HardLink, SoftLink or ExternalLink instances.  Return\n",
      " |          \"default\" if nothing with that name exists.\n",
      " |      \n",
      " |      \"getlink\" and \"getclass\" are True:\n",
      " |          Return HardLink, SoftLink and ExternalLink classes.  Return\n",
      " |          \"default\" if nothing with that name exists.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      >>> cls = group.get('foo', getclass=True)\n",
      " |      >>> if cls == SoftLink:\n",
      " |      ...     print '\"foo\" is a soft link!'\n",
      " |  \n",
      " |  move(self, source, dest)\n",
      " |      Move a link to a new location in the file.\n",
      " |      \n",
      " |      If \"source\" is a hard link, this effectively renames the object.  If\n",
      " |      \"source\" is a soft or external link, the link itself is moved, with its\n",
      " |      value unmodified.\n",
      " |  \n",
      " |  require_dataset(self, name, shape, dtype, exact=False, **kwds)\n",
      " |      Open a dataset, creating it if it doesn't exist.\n",
      " |      \n",
      " |      If keyword \"exact\" is False (default), an existing dataset must have\n",
      " |      the same shape and a conversion-compatible dtype to be returned.  If\n",
      " |      True, the shape and dtype must match exactly.\n",
      " |      \n",
      " |      Other dataset keywords (see create_dataset) may be provided, but are\n",
      " |      only used if a new dataset is to be created.\n",
      " |      \n",
      " |      Raises TypeError if an incompatible object already exists, or if the\n",
      " |      shape or dtype don't match according to the above rules.\n",
      " |  \n",
      " |  require_group(self, name)\n",
      " |      Return a group, creating it if it doesn't exist.\n",
      " |      \n",
      " |      TypeError is raised if something with that name already exists that\n",
      " |      isn't a group.\n",
      " |  \n",
      " |  visit(self, func)\n",
      " |      Recursively visit all names in this group and subgroups (HDF5 1.8).\n",
      " |      \n",
      " |      You supply a callable (function, method or callable object); it\n",
      " |      will be called exactly once for each link in this group and every\n",
      " |      group below it. Your callable must conform to the signature:\n",
      " |      \n",
      " |          func(<member name>) => <None or return value>\n",
      " |      \n",
      " |      Returning None continues iteration, returning anything else stops\n",
      " |      and immediately returns that value from the visit method.  No\n",
      " |      particular order of iteration within groups is guaranteed.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      >>> # List the entire contents of the file\n",
      " |      >>> f = File(\"foo.hdf5\")\n",
      " |      >>> list_of_names = []\n",
      " |      >>> f.visit(list_of_names.append)\n",
      " |  \n",
      " |  visititems(self, func)\n",
      " |      Recursively visit names and objects in this group (HDF5 1.8).\n",
      " |      \n",
      " |      You supply a callable (function, method or callable object); it\n",
      " |      will be called exactly once for each link in this group and every\n",
      " |      group below it. Your callable must conform to the signature:\n",
      " |      \n",
      " |          func(<member name>, <object>) => <None or return value>\n",
      " |      \n",
      " |      Returning None continues iteration, returning anything else stops\n",
      " |      and immediately returns that value from the visit method.  No\n",
      " |      particular order of iteration within groups is guaranteed.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      # Get a list of all datasets in the file\n",
      " |      >>> mylist = []\n",
      " |      >>> def func(name, obj):\n",
      " |      ...     if isinstance(obj, Dataset):\n",
      " |      ...         mylist.append(name)\n",
      " |      ...\n",
      " |      >>> f = File('foo.hdf5')\n",
      " |      >>> f.visititems(func)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h5py._hl.base.HLObject:\n",
      " |  \n",
      " |  __bool__(self)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |  \n",
      " |  __nonzero__ = __bool__(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h5py._hl.base.HLObject:\n",
      " |  \n",
      " |  file\n",
      " |      Return a File instance associated with this object\n",
      " |  \n",
      " |  id\n",
      " |      Low-level identifier appropriate for this object\n",
      " |  \n",
      " |  name\n",
      " |      Return the full name of this object.  None if anonymous.\n",
      " |  \n",
      " |  parent\n",
      " |      Return the parent group of this object.\n",
      " |      \n",
      " |      This is always equivalent to obj.file[posixpath.dirname(obj.name)].\n",
      " |      ValueError if this object is anonymous.\n",
      " |  \n",
      " |  ref\n",
      " |      An (opaque) HDF5 reference to this object\n",
      " |  \n",
      " |  regionref\n",
      " |      Create a region reference (Datasets only).\n",
      " |      \n",
      " |      The syntax is regionref[<slices>]. For example, dset.regionref[...]\n",
      " |      creates a region reference in which the whole dataset is selected.\n",
      " |      \n",
      " |      Can also be used to determine the shape of the referenced dataset\n",
      " |      (via .shape property), or the shape of the selection (via the\n",
      " |      .selection property).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h5py._hl.base.CommonStateObject:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h5py._hl.base.MappingHDF5:\n",
      " |  \n",
      " |  items(self)\n",
      " |      Get a view object on member items\n",
      " |  \n",
      " |  keys(self)\n",
      " |      Get a view object on member names\n",
      " |  \n",
      " |  values(self)\n",
      " |      Get a view object on member objects\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from collections.abc.MutableMapping:\n",
      " |  \n",
      " |  clear(self)\n",
      " |      D.clear() -> None.  Remove all items from D.\n",
      " |  \n",
      " |  pop(self, key, default=<object object at 0x7f2b77a7f130>)\n",
      " |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      " |      If key is not found, d is returned if given, otherwise KeyError is raised.\n",
      " |  \n",
      " |  popitem(self)\n",
      " |      D.popitem() -> (k, v), remove and return some (key, value) pair\n",
      " |      as a 2-tuple; but raise KeyError if D is empty.\n",
      " |  \n",
      " |  setdefault(self, key, default=None)\n",
      " |      D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D\n",
      " |  \n",
      " |  update(*args, **kwds)\n",
      " |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      " |      If E present and has a .keys() method, does:     for k in E: D[k] = E[k]\n",
      " |      If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v\n",
      " |      In either case, this is followed by: for k, v in F.items(): D[k] = v\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from collections.abc.Mapping:\n",
      " |  \n",
      " |  __reversed__ = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from collections.abc.Collection:\n",
      " |  \n",
      " |  __subclasshook__(C) from abc.ABCMeta\n",
      " |      Abstract classes can override this to customize issubclass().\n",
      " |      \n",
      " |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      " |      It should return True, False or NotImplemented.  If it returns\n",
      " |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      " |      overrides the normal algorithm (and the outcome is cached).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(h5py.File)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
